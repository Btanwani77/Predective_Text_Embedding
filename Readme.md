
# Introduction
In this paper, we propose a semi-supervised representation learning method for text data, which we call the predictive text embedding (PTE). Predictive text embedding utilizes both labeled and unlabeled data to learn the embedding of text. The labeled information and different levels of word co-occurrence information are first represented as a large-scale heterogeneous text network, which is then embedded into a low dimensional space through a principled and efficient algorithm.

### Steps to run code:
```
python train.py
python test.py
```
Link For the Dataset used:
http://ai.stanford.edu/~amaas/data/sentiment/
